
# We'll get back to you

## Sleep on your back

Some background. I was trained as an experimental psychologist. Statistically speaking, that meant a lot of ANOVA, but not even complicated ANOVA, just some standard factorial mixed design.   Continuous data? Discretize it and run ANOVA. Not doing an experiment? ANOVA anyway! The time spent on just t-tests and other overly simple bivariate relationships... just ridiculous.  Nary a word mentioned that it was a special case of more common and flexible models, I had to learn that later. I also had to take multivariate and psychometric techniques, which were among some of the least likely methods to be used in experimental psychology, but at least they started to get into something more interesting than ANOVA... like MANOVA![^manova]

There were red books often referenced (Winer, Kirk), 'modern' updates to those that still were 90% ANOVA methods... it was like some instructors had ignored all that had gone on around them, and figured everything had statistically been settled around 1984.  Don't get me wrong, 1984 wasn't all bad.  In fact it was a most excellent time in some ways[^1984]. Sure, there was some of the best entertainment humanity would ever offer, like Buckaroo Bonzai, Red Dawn, Knight Rider, Automan, Street Hawk (almost!), Danger Mouse, A-team, and Battle of the Planets; one could argue it was the heyday of fashion; the cars... MR2, 300ZX, Delorean[^dmc], Countache, 288 GTO[^lazer]! But statistically, computationally, algorithmically, many approaches to data analysis were only just beginning, as computers were becoming more and more commonplace, opening the doors of discovery.  And it is weird to me that people were, and still are, writing applied books on statistics as if this revolution did not take palce. 

Programatically my training was actually worse- SPSS, and not even really programming[^spss_syntax], just using the menus and punch-card-based syntax[^punch] to run the available procedures. No one, absolutely no one was taught basic programming principles that would have made so many things much simpler.  You pick some up along the way, but it was never focused on in the actual training.

One of my cohorts, who, lucky for me, had somehow skirted the laws regarding the length of graduate training, was regularly going on and on about R.  When I eventually got a job with him as part of the campus research support group, I gained more exposure and had some guidance to boot.  SPSS was regularly failing at doing anything even remotely beyond the basics, like calculating an effect size or incorporating robust measures.  Given my training, R was a complete pain in the ass initially, but it eventually did what I wanted, and far more easily than SPSS would have.  And every time I used it, I saw something else I could do with it, *and* I learned something new statistically or programming-wise.  It didn't take too long before there was no reason to use SPSS, and in the time since R has become the standard for statistical programming[^r4stats], while SPSS has essentially tumbled off a cliff in academic and even enterprise usage.

<a href="http://r4stats.com/articles/popularity/"><img src="https://i0.wp.com/r4stats.com/wp-content/uploads/2012/04/Fig_2d_ScholarlyImpact.png" style="display:block; margin: 0 auto;" ></img></a>

More important for a new (or any) researcher, fair or not, and despite what SPSS or similar programming skill one might have, using it is basically stating in your article that 'we probably screwed up somewhere, but we don't know because we spent all our time repeatedly clicking on the same things and didn't have time or tools for adequate data processing, exploration and visualization'.  Probably most telling is that the person who created SPSS eventually jumped ship for R himself[^nie].

The take home messages here are: that *you*, yes *you*, can go from a spreadsheet-loving menu-clicker to a 'decent-enough' programmer to take your research to the next level, and secondly, that at least some people with mullets can be trusted to provide useful information[^mullet].


Anyway, since my initial foray into statistical programming, I've consulted at three institutions, taught courses/classes at the graduate and undergraduate levels in multiple departments, consulted with people from several dozen departments and disciplines, participated in institutional research, given workshops etc.  What's more, I've gotten to hang out and share experiences with people who do the same. This is not to brag, an activity I detest, but to make a point. In all those experiences I've yet to come across an individual in academia who couldn't do what's suggested in this document.  I've certainly seen those that have zero desire to do so, and want to do the bare minimum required for their degree, or to get published, but if you're reading this, you aren't one of those.


And that's what it comes down to primarily, <span class="emph">*desire*</span>, and secondly, <span class="emph">*time*</span>, which you won't necessarily have copious amounts of as a graduate student, who has to manage classes and other aspects of life, or a faculty or other applied researcher, who may have courses, article writing, and a host of administrative duties to contend with.  Finding the balance will be one of the more difficult challenges you'll have[^powergrad].  It can be done though, and many do it all the time.



[^manova]: I'm still trying to figure out why MANOVA is being taught for any reason in 2017, but I know that it is.

[^spss_syntax]: Not that learning SPSS syntax would have been a good way to spend one's time.

[^punch]: I'm not kidding.  SPSS syntax was developed during the punch card mainframe era of the 1970s. The first release was actually 1968.  It has slightly more functionality now, though the graphics are about the same.

[^1984]: As long as you weren't a minority, ignored the economy, and didn't mind being taught to hide under your desk in case a nuclear bomb was dropped on your head.  I admit that this is a U.S. centric recollection.  I'm sure the Canadians were fine for example, though they didn't learn to flip their collars for a couple more years.

[^dmc]: Deloreans actually ceased production in 1983, but that was mostly because almost every household that could had purchased at least one and the market was exhausted.  The streets were literally cluttered with them, and many people would even leave them in parking lots with wings open, hoping someone would steal it.

[^lazer]: Insert Lazerhawk and/or Kavinsky here.



[^efron79]: *Computers and the theory of statistics: thinking the unthinkable* B Efron **1979**.  Here is the abstract: This is a survey article concerning recent advances in certain areas of statistical theory, written for a mathematical audience with no background in statistics. The topics are chosen to illustrate a special point: how the advent of the high-speed computer has affected the development of statistical theory. The topics discussed include nonparametric methods, the jackknife, the bootstrap, cross-validation, error-rate estimation in discriminant analysis, robust estimation, the influence function, censored data, the EM algorithm, and Cox's likelihood function. The exposition is mainly by example, with only a little offered in the way of theoretical development.  <br><br> I'd be willing to bet one could change nothing but the date, give this at a conference for some applied disciplines, and no one would notice.

[^r4stats]: Despite what you may see in your discipline, this is an indisputable fact at this point.  Your discipline is not statistics, computer science or other fields driving methodological development.  

[^mullet]: At least those with one like Kenny Powers from Eastbound & Down.

[^powergrad]: I've never understood the motivation behind faculty who request their graduate students do a power analysis for their dissertation or thesis. Want to know how many folks you need for your study? Here's the more appropriate question: *When* do you want to graduate?

[^nie]: Perhaps surprisingly, he did not subsequently claim to have invented R.